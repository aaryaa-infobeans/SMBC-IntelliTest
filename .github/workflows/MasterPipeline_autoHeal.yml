name: MasterTestExecution_autoHeal

on:
  # repository_dispatch:
  #   types: [xray-trigger]
  # push:
  #   branches: [master, dev]
  workflow_dispatch:
    inputs:
      mode:
        description: "Execution mode (parallel/sequential)"
        required: false
        default: "sequential"
        type: choice
        options:
          - parallel-with-pytest
          - parallel-with-custom-runner
          - sequential
      workers:
        description: "Number of parallel workers (optional) (If mode is parallel-with-pytest)"
        required: false
        default: "2"
      split_level:
        description: "Split level (module/test_file) (If mode is parallel-with-pytest)"
        required: false
        default: "module"
      env:
        description: "Environment to run tests against (If mode is parallel-with-custom-runner)"
        required: true
        default: "REL"
      # load_type:
      #   description: "Type of load to perform (If mode is parallel-with-custom-runner)"
      #   required: true
      #   default: "load"
      custom_batch_list:
        description: "List of modules to run tests against (If mode is parallel-with-custom-runner)"
        required: false
        default: "test_daily_batch"
      test_args:
        description: 'Extra pytest arguments (optional)'
        required: false
        default: ""
      xray_test_args:
        description: 'Enter Xray Test plan key or Test Execution ID (optional) in format --testplan <test_plan_key> or --execution <test_execution_id>, Also make sure the provided key should have a Jira ticket associated with it'
        required: false
        default: ""

  workflow_run:
    workflows: ["WF-Static Code Analysis"]   # Name of first workflow
    types:
      - completed

jobs:
  run_sca_first_if_manual:
    if: ${{ github.event_name == 'workflow_dispatch' }}   # Only run if triggered manually
    uses: ./.github/workflows/WF-SCA.yml   # Reuse SCA workflow
    secrets: inherit

  test-execution:
    # Ensure SCA runs and succeeds first on manual trigger; on other triggers, proceed normally
    name: Test Execution with AutoHeal
    needs: run_sca_first_if_manual
          # Run only when:
    # - Manual trigger and reusable SCA succeeded, OR
    # - Triggered by workflow_run and upstream SCA concluded success.
    # Use always() to avoid auto-skip when 'needs' is skipped on non-manual triggers.
    # if: ${{ always() && ((github.event_name == 'workflow_dispatch' && needs.run_sca_first_if_manual.result == 'success') || (github.event_name == 'workflow_run' && github.event.workflow_run.conclusion == 'success')) }}
    if: always()
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write
      issues: write
      repository-projects: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest-html-merger
          python -m playwright install chromium
          pip list

      - name: Check pip deps
        run: pip list
      
      - name: Prepare shell scripts
      # run only when mode is parallel-with-custom-runner
        if: ${{ github.event.inputs.mode == 'parallel-with-custom-runner' }}
        run: |
          sed -i 's/\r$//' pyRunner.sh
          chmod +x pyRunner.sh

      - name: Set env for pyRunner
        if: ${{ github.event.inputs.mode == 'parallel-with-custom-runner' }}
        run: echo "PROJECT_DIR=$GITHUB_WORKSPACE" >> $GITHUB_ENV

      - name: Set commit message and date as variables
        run: |
          echo "latestCommitMessage=$(git log -1 --pretty=format:'%s')" >> $GITHUB_ENV
          echo "currentDateTime=$(date +'%Y-%m-%d %H-%M')" >> $GITHUB_ENV
          echo "testExecutionStartedMessage=Project:SMBC-IntelliTest - Test Execution Started for RunId: ${{ github.run_id }} on ${{ env.currentDateTime }}, Branch: ${{ github.ref }}" >> $GITHUB_ENV
          echo "testExecutionStartedTitle=Project:SMBC-IntelliTest - Test Execution Started" >> $GITHUB_ENV
      
      - name: Slack Notification - Start
        uses: rtCamp/action-slack-notify@v2
        env:
          SLACK_CHANNEL: general
          SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK_URL }}
          SLACK_COLOR: ${{ job.status }}
          SLACK_TOKEN: ${{ secrets.SLACK_TOKEN }}
          SLACK_TITLE: ${{ env.testExecutionStartedTitle }}
          SLACK_MESSAGE: ${{ env.testExecutionStartedMessage }}
          SLACK_USERNAME: GitHub Actions
          SLACK_FOOTER: "Pytest+playwright test_automation"
        if: always()

      - name: MS Teams Message Card
        # You may pin to the exact commit or the version.
        # uses: simbo/msteams-message-card-action@d87ad6c3908b72f4fd94b55d937d05395c7300dc
        uses: simbo/msteams-message-card-action@v1.4.3
        if: always()
        with:
        # The MS Teams webhook URL to send the notification to. Obviously required.
          webhook: ${{ secrets.WEBHOOK_URL }}
            # The title of your card. Will be omitted by MS Teams if left empty.
          title: ${{ env.testExecutionStartedTitle }}
            # The message content. Supports HTML up to a certain level (interpreted by MS Teams). Can also be empty.
          message: ${{ env.testExecutionStartedMessage }}
      
      - name: Execute Tests with custom runner
        continue-on-error: true
        if: ${{ github.event.inputs.mode == 'parallel-with-custom-runner' }}
        env:
          BASE_URL: 'https://www.saucedemo.com/v1/'
        run: |
          ENV_NAME="${{ github.event.inputs.env }}"
          LOAD_TYPE="load"
          MODULES="${{ github.event.inputs.custom_batch_list }}"

          # Defaults for non-dispatch triggers
          if [ -z "$ENV_NAME" ]; then ENV_NAME="PROD"; fi
          if [ -z "$LOAD_TYPE" ]; then LOAD_TYPE="load"; fi

          if [ -z "$MODULES" ] || [ "$MODULES" = "all" ]; then
            python regression_runnner.py --config config.yaml --env "$ENV_NAME" --load_type "$LOAD_TYPE"
          else
            python regression_runnner.py --config config.yaml --env "$ENV_NAME" --load_type "$LOAD_TYPE" --active_batch_list "$MODULES"
          fi

      - name: Upload Test Reports
        if: ${{ github.event.inputs.mode == 'parallel-with-custom-runner' }}
        uses: actions/upload-artifact@v4
        with:
          name: pytest-reports
          path: |
            reports/**

      - name: Execute Tests with pytest
        id: execute_tests  # Add this ID to reference the step
        # run when mode is not parallel-with-custom-runner
        if: ${{ github.event.inputs.mode != 'parallel-with-custom-runner' }}
        continue-on-error: true
        env:
          BASE_URL: 'https://www.saucedemo.com/v1/'
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          AZURE_OPENAI_ENDPOINT: ${{ secrets.AZURE_OPENAI_ENDPOINT }}
          XRAY_API_BASE_URL: ${{ secrets.XRAY_BASE_URL || 'https://xray.cloud.getxray.app' }}
          XRAY_CLIENT_ID: ${{ secrets.XRAY_CLIENT_ID }}
          XRAY_CLIENT_SECRET: ${{ secrets.XRAY_CLIENT_SECRET }}
          XRAY_TEST_PLAN_KEY: ${{ secrets.XRAY_TEST_PLAN_KEY || 'MYS-53' }}
          XRAY_EXECUTION_SUMMARY: Smoke ${{ env.currentDateTime }}
          XRAY_EXECUTION_DESC: Test Execution after commit - ${{ env.latestCommitMessage }}

        run: |
          # Set defaults
          # Dynamically set parallel based on mode
          if [ "${{ github.event.inputs.mode }}" = "parallel-with-pytest" ]; then
            parallel="true"
          else
            parallel="false"
          fi
          
          workers="${{ github.event.inputs.workers }}"
          split="${{ github.event.inputs.split_level }}"

          # Combine additional test_args if provided
          if [ ! -z "${{ github.event.inputs.test_args }}" ]; then
            TEST_ARGS="$TEST_ARGS ${{ github.event.inputs.test_args }}"
          fi

          # Combine additional xray_test_args if provided
          if [ ! -z "${{ github.event.inputs.xray_test_args }}" ]; then
            TEST_ARGS="$TEST_ARGS ${{ github.event.inputs.xray_test_args }}"
          else
            TEST_ARGS="$TEST_ARGS --testplan ${{ secrets.XRAY_TEST_PLAN_KEY || 'MYS-53' }}"
          fi

          if [ "$parallel" = "true" ]; then
            echo "âž¡ Running in parallel mode"

            # Fallback defaults
            if [ -z "$workers" ]; then
              workers=2
            fi
            if [ -z "$split" ]; then
              split="test_file"
            fi

            echo "Workers: $workers | Split level: $split"

            if [ "$split" = "module" ]; then
              echo "âž¡ Running parallaly"
              python -m pytest $TEST_ARGS --jira-xray --client-secret-auth --cloud -v -n "$workers" --dist=loadscope --junitxml=test-results.xml --json-report --json-report-file=test-results.json || echo "TEST_FAILED=1" >> $GITHUB_ENV
            else
              python -m pytest $TEST_ARGS --jira-xray --client-secret-auth --cloud -v -n "$workers" --dist=loadfile --junitxml=test-results.xml --json-report --json-report-file=test-results.json || echo "TEST_FAILED=1" >> $GITHUB_ENV
            fi

          else
            echo "âž¡ Running sequentially"
            python -m pytest $TEST_ARGS --testplan MYS-53 --jira-xray --client-secret-auth --cloud -v --junitxml=test-results.xml --json-report --json-report-file=test-results.json || echo "TEST_FAILED=1" >> $GITHUB_ENV
          fi


      - name: Auto-healing (if failed)
        if: env.TEST_FAILED == '1'
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          AZURE_OPENAI_ENDPOINT: ${{ secrets.AZURE_OPENAI_ENDPOINT }}
        run: |
          python Utilities/TestUtils/autoheal_agent.py

      - name: Check for AutoHeal changes in SRC/pages
        if: env.TEST_FAILED == '1'
        id: check-changes
        run: |
          if git diff --quiet -- SRC/pages/; then
            echo "has_changes=false" >> $GITHUB_OUTPUT
            echo "No files were modified by AutoHeal in SRC/pages/"
          else
            echo "has_changes=true" >> $GITHUB_OUTPUT
            echo "Files modified by AutoHeal in SRC/pages/:"
            git diff --name-only -- SRC/pages/
          fi

      - name: Create Pull Request for AutoHeal fixes
        if: env.TEST_FAILED == '1' && steps.check-changes.outputs.has_changes == 'true'
        uses: peter-evans/create-pull-request@v6
        with:
          token: ${{ secrets.GH_TOKEN }}
          commit-message: "ðŸ”§ AutoHeal: Fix failing test locators"
          author: ${{ github.actor }} <${{ github.actor }}@users.noreply.github.com>
          branch: autoheal/locator-fixes-${{ github.run_id }}
          branch-suffix: short-commit-hash
          title: "ðŸ”§ AutoHeal: Fix page object locators from run #${{ github.run_id }}"
          body: |
            ## ðŸ”§ AutoHeal Page Object Locator Fixes
            
            This PR contains automated locator fixes for **page objects only** (`SRC/pages/`) detected by the AutoHeal system.
            
            ### ðŸŽ¯ Details
            - **Trigger**: Test execution run #${{ github.run_id }}
            - **Branch**: `${{ github.ref_name }}`
            - **Commit**: ${{ github.sha }}
            - **Workflow**: ${{ github.workflow }}
            - **Scope**: `SRC/pages/*.py` files only
            
            ### ðŸ”„ Changes Applied
            The AutoHeal agent analyzed failed locators in page object files and applied AI-suggested improvements.
            
            ### ðŸ§ª Testing Required
            Please review the changes and verify that:
            1. The new locators are more robust and reliable
            2. All affected tests pass with the updated page object locators
            3. No unintended side effects are introduced in page object interactions
            
            ### ðŸ“‹ Files Changed
            Only page object files in `SRC/pages/` directory are included in this PR.
            Check the "Files changed" tab to see all locator modifications.
            
            ---
            *ðŸ¤– This PR was automatically created by AutoHeal based on AI analysis of test failures.*
          labels: |
            autoheal
            locator-fix
            ai-suggested
            needs-testing
          assignees: ${{ github.actor }}
          draft: false
          delete-branch: true
          add-paths: |
            SRC/pages/*.py

      - name: Upload AutoHeal Debug Files
        if: always() && env.TEST_FAILED == '1'
        uses: actions/upload-artifact@v4
        with:
          name: autoheal-debug-files
          path: |
            reports/captured_locator_failures.json
            reports/dom_snapshot_*.html
          if-no-files-found: ignore

      - name: Extract test statistics
        id: extract-stats
        if: always()
        run: |
          if [ -f test-results.json ]; then
            echo "passed=$(python -c "import json; data=json.load(open('test-results.json')); print(data.get('summary', {}).get('passed', 0))")" >> $GITHUB_OUTPUT
            echo "failed=$(python -c "import json; data=json.load(open('test-results.json')); print(data.get('summary', {}).get('failed', 0))")" >> $GITHUB_OUTPUT
            echo "skipped=$(python -c "import json; data=json.load(open('test-results.json')); print(data.get('summary', {}).get('skipped', 0))")" >> $GITHUB_OUTPUT
            echo "total=$(python -c "import json; data=json.load(open('test-results.json')); print(data.get('summary', {}).get('total', 0))")" >> $GITHUB_OUTPUT
          else
            echo "passed=0" >> $GITHUB_OUTPUT
            echo "failed=0" >> $GITHUB_OUTPUT
            echo "skipped=0" >> $GITHUB_OUTPUT
            echo "total=0" >> $GITHUB_OUTPUT
          fi

      - name: Set timestamp
        if: always()
        run: |
          echo "TIMESTAMP=$(date +'%Y-%m-%d_%H-%M-%S')" >> $GITHUB_ENV
          echo "TIMESTAMPFORSUBJECT=$(date +'%m-%d-%Y %H:%M:%S')" >> $GITHUB_ENV
          echo "ZipReportName=ExecutionReport_$(date +'%Y-%m-%d_%H-%M-%S').zip" >> $GITHUB_ENV
          echo "testExecutionCompletedMessage=Project:SMBC-IntelliTest - Test Execution Completed for RunId: ${{ github.run_id }} on ${{ env.currentDateTime }}, status: ${{ steps.execute_tests.outcome }} Branch: ${{ github.ref }}" >> $GITHUB_ENV
          echo "testExecutionCompletedTitle=Project:SMBC-IntelliTest - Test Execution Completed" >> $GITHUB_ENV

      - name: Generate pytest report
        if: always()
        run: python Utilities/ReportUtils/generate_pytest_report.py

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
  
      - name: Install Allure CLI via npm
        run: |
          npm install -g allure-commandline
          allure --version
  
      - name: Generate Allure report
        run: |
          allure generate allure-results --clean -o allure-report
  
      - name: Install allure-combine and generate single file
        run: |
          pip install allure-combine
          allure-combine ./allure-report
  
      - name: Upload Allure single HTML report
        uses: actions/upload-artifact@v4
        with:
          name: allure-report-single-file
          path: allure-report/complete.html

      - name: Upload PDF Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pytest_execution_report
          path: SMBC-IntelliTest_test_summary.pdf

      - name: Upload test results to GitHub
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: |
            test-results.xml
            test-results.json
            allure-results/
            SMBC-IntelliTest_allure_report.html
          retention-days: 30

      - name: Upload Allure Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: allure-results
          path: allure-results
          
      # To be used when GH -pages are subscribed =======until this marker below=================================================
      # - name: Load test report history
      #   uses: actions/checkout@v3
      #   if: always()
      #   continue-on-error: true
      #   with:
      #     ref: gh-pages
      #     path: gh-pages

      # - name: Build test report
      #   uses: simple-elf/allure-report-action@v1.7
      #   if: always()
      #   with:
      #     gh_pages: gh-pages
      #     allure_history: allure-history
      #     allure_results: allure-results

      # - name: Publish test report
      #   uses: peaceiris/actions-gh-pages@v3
      #   if: always()
      #   with:
      #     github_token: ${{ secrets.GITHUB_TOKEN }}
      #     publish_branch: gh-pages
      #     publish_dir: allure-history
      #     force_orphan: true
      # =================================================================================

      - name: Prepare email HTML body
        id: prepare-email
        if: always()
        run: |
          # Export environment variables for the script
          export TEST_RESULT="${{ env.TEST_FAILED == '1' && 'FAILED' || 'PASSED' }}"
          export TOTAL_TESTS="${{ steps.extract-stats.outputs.total }}"
          export PASSED_TESTS="${{ steps.extract-stats.outputs.passed }}"
          export FAILED_TESTS="${{ steps.extract-stats.outputs.failed }}"
          export SKIPPED_TESTS="${{ steps.extract-stats.outputs.skipped }}"
          
          # Run the script to prepare the email body
          python .github/scripts/prepare_email_body.py
          
          # Read the generated HTML file and set it as output
          echo "email_body<<EOF" >> $GITHUB_OUTPUT
          cat email-body.html >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Generate test artifacts
        if: always()
        run: |
          # Create a zip file with test results
          zip -r "${{ env.ZipReportName }}" test-results.json test-results.xml || true

      - name: Send email notification
        if: always()
        uses: dawidd6/action-send-mail@v6
        with:
          server_address: smtp.gmail.com
          server_port: 587
          username: ${{ secrets.GMAIL_USERNAME }}
          password: ${{ secrets.GMAIL_APP_PASSWORD }}
          subject: "SMBC-IntelliTest Test Execution updates: ${{ env.TEST_FAILED == '1' && 'FAILED' || 'PASSED' }} at ${{ env.TIMESTAMPFORSUBJECT }}"
          to: ${{ secrets.NOTIFICATION_EMAIL }}
          from: "SMBC-IntelliTest Testing Team <${{ secrets.GMAIL_USERNAME }}>"
          html_body: ${{ steps.prepare-email.outputs.email_body }}
          attachments: "${{ env.ZipReportName }},SMBC-IntelliTest_test_summary.pdf,SMBC-IntelliTest_allure_report.html"

      - name: Slack Summary - Post execution
        if: always()
        uses: rtCamp/action-slack-notify@v2
        env:
          SLACK_CHANNEL: general
          SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK_URL }}
          SLACK_COLOR: ${{ job.status }}
          SLACK_TOKEN: ${{ secrets.SLACK_TOKEN }}
          SLACK_TITLE: ${{ env.testExecutionCompletedTitle }}
          SLACK_MESSAGE: ${{ env.testExecutionCompletedMessage }}
          SLACK_USERNAME: GitHub Actions
          SLACK_FOOTER: "Pytest+playwright test_automation"
      
      - name: MS Teams Summary - Post execution
        if: always()
        uses: simbo/msteams-message-card-action@v1.4.3
        with:
          webhook: ${{ secrets.WEBHOOK_URL }}
          title: ${{ env.testExecutionCompletedTitle }}
          message: ${{ env.testExecutionCompletedMessage }}
